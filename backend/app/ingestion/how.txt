PDFs
 â†“
loader.py        â†’ load_pdfs_from_directory()
 â†“
chunker.py       â†’ chunk_documents()
 â†“
embedder.py      â†’ get_embedding_model()
 â†“
indexer.py       â†’ create_or_update_vector_store()
 â†“
FAISS (trusted KB)


ğŸ“‚ ingestion/loader.py
 Responsibility: Load institute PDFs into LangChain Documents
Uses official LangChain PDF loader
Preserves page-level metadata
Adds source â†’ crucial for explainability

ğŸ“‚ ingestion/chunker.py
 Responsibility: Convert raw documents â†’ semantic chunks
800 tokens â†’ preserves concept-level context
150 overlap â†’ avoids broken explanations
Recursive splitter â†’ best default for PDFs

ğŸ“‚ ingestion/embedder.py
Responsibility: Initialize HuggingFace embedding model
model_name="sentence-transformers/all-MiniLM-L6-v2",

ğŸ“‚ ingestion/indexer.py
 Responsibility: Store chunks in FAISS vector DB
Supports incremental ingestion
Faculty can upload content multiple times
Local FAISS â†’ zero infra


ğŸ¯ What You Can Say in a Review / Interview

â€œThe ingestion pipeline is deterministic, semantic-aware, and restricted to faculty-uploaded content. Chunking is optimized for concept integrity, and embeddings are open-source to ensure institutional control.â€